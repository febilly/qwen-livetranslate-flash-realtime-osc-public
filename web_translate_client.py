import os
import time
import base64
import asyncio
import json
import websockets
import traceback
from osc_manager import osc_manager

class WebTranslateClient:
    """ä¸“é—¨ç”¨äºWebç¯å¢ƒçš„ç¿»è¯‘å®¢æˆ·ç«¯ï¼Œä¸ä¾èµ–pyaudio"""
    
    def __init__(self, api_key: str, target_language: str = "en", voice: str | None = "Cherry", *, audio_enabled: bool = True, osc_mute_control: bool = True, send_to_osc: bool = True):
        if not api_key:
            raise ValueError("API key cannot be empty.")
            
        self.api_key = api_key
        self.target_language = target_language
        self.audio_enabled = audio_enabled
        self.voice = voice if audio_enabled else "Cherry"
        self.ws = None
        self.api_url = "wss://dashscope.aliyuncs.com/api-ws/v1/realtime?model=qwen3-livetranslate-flash-realtime"
        
        # éŸ³é¢‘é…ç½®ï¼ˆä»…ç”¨äºé…ç½®ï¼Œä¸éœ€è¦pyaudioï¼‰
        self.input_rate = 16000
        self.input_channels = 1
        self.output_rate = 24000
        self.output_channels = 1
        
        # çŠ¶æ€ç®¡ç†
        self.is_connected = False
        
        # è¯­éŸ³å¤„ç†æ§åˆ¶ï¼šé»˜è®¤ä¸ºTrueè¡¨ç¤ºå¤„ç†è¯­éŸ³æ•°æ®
        self.is_processing_audio = True
        
        # OSCé™éŸ³æ§åˆ¶å¼€å…³ï¼šæ§åˆ¶æ˜¯å¦å“åº”OSCé™éŸ³æ¶ˆæ¯
        self.osc_mute_control_enabled = osc_mute_control
        
        # OSCå‘é€å¼€å…³ï¼šæ§åˆ¶æ˜¯å¦å‘é€ç¿»è¯‘ç»“æœåˆ°OSC
        self.send_to_osc_enabled = send_to_osc
        
        # ç¿»è¯‘è€—æ—¶ç»Ÿè®¡
        self.translation_start_time = None

    async def pause_audio_processing(self):
        """æš‚åœå¤„ç†è¯­éŸ³æ•°æ®"""
        if self.is_processing_audio:  # åªåœ¨å¤„ç†ä¸­æ—¶æ‰æ‰§è¡Œæš‚åœé€»è¾‘
            self.is_processing_audio = False
            # è®°å½•ç¿»è¯‘å¼€å§‹æ—¶é—´
            import time
            self.translation_start_time = time.time()
            timestamp = time.strftime("%H:%M:%S")
            print(f"[{timestamp}] [WebTranslateClient] â±ï¸ å¼€å§‹ç¿»è¯‘è®¡æ—¶")
            print(f"[WebTranslateClient] æš‚åœå¤„ç†è¯­éŸ³æ•°æ®")
            
            # å‘é€1ç§’çš„ç©ºç™½éŸ³é¢‘è¡¨ç¤ºè¯­éŸ³ç»“æŸ
            await self._send_silence(duration_seconds=3.0)

    def resume_audio_processing(self):
        """æ¢å¤å¤„ç†è¯­éŸ³æ•°æ®"""
        self.is_processing_audio = True
        print(f"[WebTranslateClient] æ¢å¤å¤„ç†è¯­éŸ³æ•°æ®")
    
    def update_token_usage(self, usage: dict):
        """æ›´æ–°tokenä½¿ç”¨ç»Ÿè®¡
        
        Args:
            usage: åŒ…å«tokenä½¿ç”¨ä¿¡æ¯çš„å­—å…¸
        """
        if not usage:
            return
        
        # æå–æœ¬æ¬¡ä½¿ç”¨çš„tokenæ•°
        total = usage.get("total_tokens", 0)
        input_tokens = usage.get("input_tokens", 0)
        output_tokens = usage.get("output_tokens", 0)
        
        # è¾“å…¥tokenè¯¦æƒ…
        input_details = usage.get("input_tokens_details", {})
        input_text = input_details.get("text_tokens", 0)
        input_audio = input_details.get("audio_tokens", 0)
        
        # è¾“å‡ºtokenè¯¦æƒ…
        output_details = usage.get("output_tokens_details", {})
        output_text = output_details.get("text_tokens", 0)
        output_audio = output_details.get("audio_tokens", 0)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        import time
        timestamp = time.strftime("%H:%M:%S")
        # é˜¿é‡Œäº‘æ€ä¹ˆåˆå·æ”¹apiäº†ï¼Ÿï¼Ÿ
        # print(f"[{timestamp}] ğŸ“Š ç´¯è®¡: è¾“å…¥{input_tokens}(æ–‡æœ¬{input_text}+è¯­éŸ³{input_audio}) è¾“å‡º{output_tokens}(æ–‡æœ¬{output_text}+è¯­éŸ³{output_audio}) æ€»è®¡{total}")
    
    async def _send_silence(self, duration_seconds: float = 1.0):
        """å‘é€ç©ºç™½éŸ³é¢‘æ•°æ®
        
        Args:
            duration_seconds: ç©ºç™½éŸ³é¢‘çš„æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        if not self.is_connected or not self.ws:
            return
        
        try:
            # è®¡ç®—éœ€è¦çš„æ ·æœ¬æ•°é‡
            # input_rate = 16000 Hz, 1 channel, 16-bit (2 bytes per sample)
            num_samples = int(self.input_rate * duration_seconds)
            silence_data = b'\x00' * (num_samples * 2)  # 2 bytes per sample
            
            import time
            timestamp = time.strftime("%H:%M:%S")
            print(f"[{timestamp}] å‘é€{duration_seconds}ç§’ç©ºç™½éŸ³é¢‘ ({len(silence_data)} bytes)")
            
            event = {
                "event_id": f"event_{int(time.time() * 1000)}",
                "type": "input_audio_buffer.append",
                "audio": base64.b64encode(silence_data).decode()
            }
            await self.ws.send(json.dumps(event))
        except Exception as e:
            print(f"å‘é€ç©ºç™½éŸ³é¢‘å¤±è´¥: {e}")

    async def send_osc_text(self, text: str, ongoing: bool):
        """å‘é€æ–‡æœ¬åˆ°OSCèŠå¤©æ¡†"""
        # å¦‚æœæ˜¯å‘é€æœ€ç»ˆç»“æœï¼ˆä¸æ˜¯è¿›è¡Œä¸­ï¼‰ï¼Œè®¡ç®—è€—æ—¶
        if not ongoing and self.translation_start_time is not None:
            import time
            elapsed_time = time.time() - self.translation_start_time
            timestamp = time.strftime("%H:%M:%S")
            print(f"[{timestamp}] âœ… ç¿»è¯‘å®Œæˆ - è€—æ—¶: {elapsed_time:.2f}ç§’")
            self.translation_start_time = None
        
        await osc_manager.send_text(text, ongoing, self.send_to_osc_enabled)

    async def connect(self):
        """å»ºç«‹åˆ°ç¿»è¯‘æœåŠ¡çš„ WebSocket è¿æ¥ã€‚"""
        headers = {"Authorization": f"Bearer {self.api_key}"}
        try:
            self.ws = await websockets.connect(self.api_url, additional_headers=headers)
            self.is_connected = True
            pass # print(f"æˆåŠŸè¿æ¥åˆ°æœåŠ¡å™¨: {self.api_url}")
            await self.configure_session()
        except Exception as e:
            pass # print(f"è¿æ¥å¤±è´¥: {e}")
            self.is_connected = False
            raise

    async def configure_session(self):
        """é…ç½®ç¿»è¯‘ä¼šè¯ï¼Œè®¾ç½®ç›®æ ‡è¯­è¨€ã€å£°éŸ³ç­‰ã€‚"""
        config = {
            "event_id": f"event_{int(time.time() * 1000)}",
            "type": "session.update",
            "session": {
                # 'modalities' æ§åˆ¶è¾“å‡ºç±»å‹ã€‚
                # ["text", "audio"]: åŒæ—¶è¿”å›ç¿»è¯‘æ–‡æœ¬å’ŒåˆæˆéŸ³é¢‘ï¼ˆæ¨èï¼‰ã€‚
                # ["text"]: ä»…è¿”å›ç¿»è¯‘æ–‡æœ¬ã€‚
                "modalities": ["text", "audio"] if self.audio_enabled else ["text"],
                **({"voice": self.voice} if self.audio_enabled and self.voice else {}),
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "translation": {
                    "language": self.target_language
                }
            }
        }
        pass # print(f"å‘é€ä¼šè¯é…ç½®: {json.dumps(config, indent=2, ensure_ascii=False)}")
        await self.ws.send(json.dumps(config))

    async def update_session(self, *, target_language: str | None = None, voice: str | None = None, audio_enabled: bool | None = None):
        """åŠ¨æ€æ›´æ–°ä¼šè¯é…ç½®ï¼ˆè¯­è¨€/éŸ³è‰²/è¾“å‡ºé€šé“ï¼‰ã€‚"""
        if target_language is not None:
            self.target_language = target_language
        if voice is not None:
            self.voice = voice
        if audio_enabled is not None:
            self.audio_enabled = audio_enabled

        config = {
            "event_id": f"event_{int(time.time() * 1000)}",
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"] if self.audio_enabled else ["text"],
                **({"voice": self.voice} if self.audio_enabled and self.voice else {}),
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "translation": {
                    "language": self.target_language
                }
            }
        }
        pass # print(f"[update_session] å‘é€ä¼šè¯æ›´æ–°: {json.dumps(config, indent=2, ensure_ascii=False)}")
        await self.ws.send(json.dumps(config))

    async def send_audio_chunk(self, audio_data: bytes):
        """å°†éŸ³é¢‘æ•°æ®å—ç¼–ç å¹¶å‘é€åˆ°æœåŠ¡å™¨ã€‚"""
        if not self.is_connected:
            return
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†è¯­éŸ³æ•°æ®
        if not self.is_processing_audio:
            # ä¸å¤„ç†çš„è¯ï¼Œç›´æ¥ä¸¢å¼ƒæ–°çš„æ•°æ®æ®µ
            import time
            timestamp = time.strftime("%H:%M:%S")
            pass # print(f"[{timestamp}] è¯­éŸ³å¤„ç†å·²æš‚åœï¼Œä¸¢å¼ƒéŸ³é¢‘æ•°æ®: {len(audio_data)} bytes")
            return
        
        import time    
        timestamp = time.strftime("%H:%M:%S")
        pass # print(f"[{timestamp}] WebTranslateClientå‘é€éŸ³é¢‘åˆ°æ¨¡å‹: {len(audio_data)} bytes")
            
        event = {
            "event_id": f"event_{int(time.time() * 1000)}",
            "type": "input_audio_buffer.append",
            "audio": base64.b64encode(audio_data).decode()
        }
        await self.ws.send(json.dumps(event))

    async def send_image_frame(self, image_bytes: bytes, *, event_id: str | None = None):
        """å°†å•å¸§å›¾åƒæ•°æ®å‘é€åˆ°æœåŠ¡å™¨ã€‚

        çº¦æŸ:
        1. å›¾åƒæ ¼å¼: JPG/JPEGï¼Œæ¨èåˆ†è¾¨ç‡ 480p/720pï¼Œæœ€å¤§ 1080pã€‚
        2. å•å¼ å¤§å° â‰¤ 500KBã€‚
        3. æ•°æ®é¡»ä½¿ç”¨ Base64 ç¼–ç ã€‚
        4. å»ºè®®å‘é€é¢‘ç‡: 2 å¼ /ç§’ã€‚
        5. å…ˆå‘é€éŸ³é¢‘ï¼Œå†å‘é€å›¾åƒã€‚
        6. æˆå¯¹ä½¿ç”¨ input_audio_buffer.commit æäº¤è§†é¢‘ç¼“å†²åŒºã€‚
        """

        if not self.is_connected:
            return

        if not image_bytes:
            raise ValueError("image_bytes ä¸èƒ½ä¸ºç©º")

        # ç¼–ç ä¸º Base64
        image_b64 = base64.b64encode(image_bytes).decode()

        event = {
            "event_id": event_id or f"event_{int(time.time() * 1000)}",
            "type": "input_image_buffer.append",
            "image": image_b64,
        }

        await self.ws.send(json.dumps(event))

    async def handle_server_messages(self, on_text_received, on_audio_received=None):
        """å¾ªç¯å¤„ç†æ¥è‡ªæœåŠ¡å™¨çš„æ¶ˆæ¯ã€‚
        
        Args:
            on_text_received: æ–‡æœ¬å›è°ƒå‡½æ•°
            on_audio_received: éŸ³é¢‘å›è°ƒå‡½æ•°ï¼ˆå¯é€‰ï¼Œç”¨äºWebç¯å¢ƒï¼‰
        """
        try:
            async for message in self.ws:
                import time
                timestamp = time.strftime("%H:%M:%S")
                # å…¼å®¹æ–‡æœ¬/äºŒè¿›åˆ¶æ¶ˆæ¯
                if isinstance(message, (bytes, bytearray)):
                    try:
                        message = message.decode('utf-8', errors='ignore')
                    except Exception:
                        continue
                
                event = json.loads(message)
                event_type = event.get("type")
                pass # print(f"[{timestamp}] WebTranslateClientæ¥æ”¶åˆ°äº‹ä»¶: {event_type}")
                
                if event_type == "response.audio_transcript.delta":
                    text = event.get("transcript", "")
                    pass # print(f"[{timestamp}] æ¥æ”¶åˆ°ç¿»è¯‘æ–‡æœ¬ç‰‡æ®µ: '{text}'")
                    if text and on_text_received:
                        on_text_received(text)
                elif event_type == "response.text.delta":
                    text = event.get("delta", "")
                    pass # print(f"[{timestamp}] æ¥æ”¶åˆ°æ–‡æœ¬delta: '{text}'")
                    if text and on_text_received:
                        on_text_received(text)
                elif event_type == "response.output_text.delta":
                    text = event.get("delta", "")
                    pass # print(f"[{timestamp}] æ¥æ”¶åˆ°output_text delta: '{text}'")
                    if text and on_text_received:
                        on_text_received(text)
                
                elif event_type == "response.audio.delta" and self.audio_enabled:
                    audio_b64 = event.get("delta", "")
                    if audio_b64:
                        audio_data = base64.b64decode(audio_b64)
                        pass # print(f"[{timestamp}] æ¥æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(audio_data)} bytes (base64é•¿åº¦: {len(audio_b64)})")
                        if on_audio_received:
                            await on_audio_received(audio_data)
                        else:
                            pass # print(f"[{timestamp}] è­¦å‘Šï¼šæ²¡æœ‰éŸ³é¢‘å›è°ƒå‡½æ•°")
                    else:
                        pass # print(f"[{timestamp}] éŸ³é¢‘deltaä¸ºç©º")

                elif event_type == "response.done":
                    pass # print(f"[{timestamp}] ä¸€è½®å“åº”å®Œæˆã€‚")
                    usage = event.get("response", {}).get("usage", {})
                    if usage:
                        # æ›´æ–°å¹¶æ˜¾ç¤ºtokenç»Ÿè®¡
                        self.update_token_usage(usage)
                        
                elif event_type == "response.audio_transcript.done":
                    pass # print(f"[{timestamp}] ç¿»è¯‘æ–‡æœ¬å®Œæˆã€‚")
                    text = event.get("transcript", "")
                    if text:
                        print(f"[{timestamp}] audio_transcript å®Œæ•´ç¿»è¯‘æ–‡æœ¬: {text}")
                        if on_text_received:
                            on_text_received(text)
                        
                elif event_type == "response.text.done":
                    pass # print(f"[{timestamp}] ç¿»è¯‘æ–‡æœ¬å®Œæˆã€‚")
                    text = event.get("text", "")
                    if text:
                        print(f"[{timestamp}] {text}")
                        await self.send_osc_text(text, False)  # å‘é€åˆ°OSC                            
                        if on_text_received:
                            on_text_received(text)
                # åˆ é™¤é‡å¤åˆ†æ”¯ï¼šå·²åœ¨ä¸Šæ–¹ç»Ÿä¸€å¤„ç† response.audio_transcript.done
                        
                elif event_type == "session.updated":
                    pass # print(f"[{timestamp}] ä¼šè¯é…ç½®å·²æ›´æ–°")
                    
                else:
                    pass # print(f"[{timestamp}] æœªå¤„ç†çš„äº‹ä»¶ç±»å‹: {event_type}")
                    # if len(str(event)) < 500:  # åªæ‰“å°çŸ­æ¶ˆæ¯
                        # print(f"[{timestamp}] äº‹ä»¶å†…å®¹: {event}")
                    
                    # ä¸å®Œæ•´çš„è¯†åˆ«
                    if 'text' in event:
                        # æ‹¼æ¥ç»“æœ
                        result = event['text']
                        if event['stash'].startswith(' '):
                            result += f" ... [{event['stash'][1:]}]"
                        else:
                            result += f" ... [{event['stash']}]"

                        print(f"[{timestamp}] {result}")
                        await self.send_osc_text(result, True)  # å‘é€åˆ°OSC                            
                            
        except websockets.exceptions.ConnectionClosed as e:
            pass # print(f"[WARNING] è¿æ¥å·²å…³é—­: {e}")
            self.is_connected = False
        except Exception as e:
            pass # print(f"[ERROR] æ¶ˆæ¯å¤„ç†æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            traceback.print_exc()
            self.is_connected = False

    async def close(self):
        """ä¼˜é›…åœ°å…³é—­è¿æ¥å’Œèµ„æºã€‚"""
        self.is_connected = False
        if self.ws:
            await self.ws.close()
            pass # print("WebSocket è¿æ¥å·²å…³é—­ã€‚")
